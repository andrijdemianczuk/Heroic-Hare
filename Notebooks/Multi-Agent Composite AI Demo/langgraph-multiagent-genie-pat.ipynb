{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae2ef0d2-0c53-45d3-9b2f-281ac1bcd43d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Mosaic AI Agent Framework: Author and deploy a multi-agent system with Genie\n",
    "\n",
    "This notebook demonstrates how to build a multi-agent system using Mosaic AI Agent Framework and [LangGraph](https://blog.langchain.dev/langgraph-multi-agent-workflows/), where [Genie](https://www.databricks.com/product/ai-bi/genie) is one of the agents.\n",
    "In this notebook, you:\n",
    "1. Author a multi-agent system using LangGraph.\n",
    "1. Wrap the LangGraph agent with MLflow `ChatAgent` to ensure compatibility with Databricks features.\n",
    "1. Manually test the multi-agent system's output.\n",
    "1. Log and deploy the multi-agent system.\n",
    "\n",
    "This example is based on [LangGraph documentation - Multi-agent supervisor example](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/multi_agent/agent_supervisor.ipynb)\n",
    "\n",
    "## Why use a Genie agent?\n",
    "\n",
    "Multi-agent systems consist of multiple AI agents working together, each with specialized capabilities. As one of those agents, Genie allows users to interact with their structured data using natural language.\n",
    "\n",
    "Unlike SQL functions which can only run pre-defined queries, Genie has the flexibility to create novel queries to answer user questions.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Address all `TODO`s in this notebook.\n",
    "- Create a Genie Space, see Databricks documentation ([AWS](https://docs.databricks.com/aws/genie/set-up) | [Azure](https://learn.microsoft.com/azure/databricks/genie/set-up))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fad5bdf5-8ab6-40ad-8b7f-71589b07dde4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install the databricks dependencies"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqq mlflow langgraph==0.3.4 databricks-langchain databricks-agents uv\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d402207-8884-456d-8e29-dce582e48dd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Define the multi-agent system\n",
    "\n",
    "Create a multi-agent system in LangGraph using a supervisor agent node directing the following agent nodes:\n",
    "- **GenieAgent**: The Genie agent that queries and reasons over structured data.\n",
    "- **Tool-calling agent**: An agent that calls Unity Catalog function tools.\n",
    "\n",
    "In this example, the tool-calling agent uses the built-in Unity Catalog function `system.ai.python_exec` to execute Python code.\n",
    "For examples of other tools you can add to your agents, see Databricks documentation ([AWS](https://docs.databricks.com/aws/generative-ai/agent-framework/agent-tool) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/agent-framework/agent-tool)).\n",
    "\n",
    "\n",
    "#### Wrap the LangGraph agent using the `ChatAgent` interface\n",
    "\n",
    "Databricks recommends using `ChatAgent` to ensure compatibility with Databricks AI features and to simplify authoring multi-turn conversational agents using an open source standard. \n",
    "\n",
    "The `LangGraphChatAgent` class implements the `ChatAgent` interface to wrap the LangGraph agent.\n",
    "\n",
    "See MLflow's [ChatAgent documentation](https://mlflow.org/docs/latest/python_api/mlflow.pyfunc.html#mlflow.pyfunc.ChatAgent).\n",
    "\n",
    "#### Write agent code to file\n",
    "\n",
    "Define the agent code in a single cell below. This lets you write the agent code to a local Python file, using the `%%writefile` magic command, for subsequent logging and deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9e11be1-5a67-434f-9faf-440bef1aa556",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A compenent-based compound AI system\n",
    "\n",
    "<img src=\"https://docs.databricks.com/aws/en/assets/images/multi-agent-framework-63c273cb78929a1904fec94e34611e38.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c62da829-e68f-4b6e-bd6e-23672c885e3f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install MLFlow 3.0"
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow  --upgrade --pre\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e70589b6-bebc-4657-ad44-0c7fe558a5ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Writing an external file\n",
    "Since we'll likely be updating this notebook over the course of time, running a check to see if a previous version exists is a good idea. We will make sure to remove it if it does exist otherwise we run the risk of appending new code to old without overwriting previous functionality. This ambuguity is likely to cause runtime errors so it's better to remove the old file first in lieu of the new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12fa25e0-3f18-4149-b872-79dfd25e7b1b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "If a previous run created a multi_agent.py file, then delete it"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Check if the multi_agent.py file exists and delete it if it does\n",
    "#This is what allows us to run the notebook over again. If our logic changes, we can also ensure we're not appending garabage to the file or screwing it up.\n",
    "\n",
    "if os.path.exists(\"multi_agent.py\"):\n",
    "    os.remove(\"multi_agent.py\")\n",
    "    print(\"multi_agent.py has been deleted.\")\n",
    "else:\n",
    "    print(\"multi_agent.py does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cda00ba3-83c6-4359-af66-f56c6dc55492",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Dependencies and third-party libraries\n",
    "Assuming that this will be coalesced into a single file, it's also important that we manage our imports at the top of the file so all functions have access to what they need. I typically break my imports into blocks of related libraries to make management easier in the long-term. Adding category descriptors also helps keep things organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aebb9e3-b873-4e6e-bd30-334739350d9a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Imports"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a multi_agent.py\n",
    "#Python libs\n",
    "import functools\n",
    "import os\n",
    "from typing import Any, Generator, Literal, Optional\n",
    "\n",
    "#Databricks sdk & Databricks langchain implementation\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    UCFunctionToolkit,\n",
    ")\n",
    "from databricks_langchain.genie import GenieAgent\n",
    "\n",
    "#Langchain tools (langraph is our agent lib)\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.agents import AgentType, initialize_agent, agent\n",
    "\n",
    "#MLflow stuff\n",
    "import mlflow\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "\n",
    "#Parsing libs\n",
    "from pydantic import BaseModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51df90f1-1915-4fe2-892e-ecadb99c5fda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating Genie Agents\n",
    "Databricks Genie now includes the Genie Spaces API. This allows us to easily define and interact with different genie rooms in an agentic fashion. With proper labeling and descriptions, the supervisor that will be managing conversions will have context awareness of each agent's capabilities. This is how we scope out and identify which agent is used for each conversational turn. Turns can either be with the user in the form of prompts, or internally with the supervisor agent. One thing that might seem confusing is the block containing the `host` and `token` values. These are placeholder values that will be injected with the real values from the parent function later on. Since we won't have access to the `dbutils` API within the agent (as it's an fully encapsulated object) we'll have to rely on the fact that these agent nodes will be invoked from a parent or 'calling' entity of some type.\n",
    "<br/>\n",
    "<br/>\n",
    "(example)\n",
    "```python\n",
    "        host=os.getenv(\"DB_MODEL_SERVING_HOST_URL\"),\n",
    "        token=os.getenv(\"DATABRICKS_GENIE_PAT\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86508d42-6b38-4b5d-9807-86358f1f814f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create the genie agents"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a multi_agent.py\n",
    "#You can find the ID in the URL of the genie room /genie/rooms/<GENIE_SPACE_ID>\n",
    "#In lieu of the locally scoped variable for the PAT, we'll use the one from our secrets store for security.\n",
    "\n",
    "GENIE_SPACE_ID_1 = \"01f026a703761605b18fa1d904cf1a64\"\n",
    "genie_agent_description_1 = \"This genie agent can answer any questions around billing and Databricks or AWS related expenses associated with the account. It is assumed that all relevant billing data is included in this agent.\"\n",
    "\n",
    "genie_agent_1 = GenieAgent(\n",
    "    genie_space_id=GENIE_SPACE_ID_1,\n",
    "    genie_agent_name=\"Genie_DBX_Cost\",\n",
    "    description=genie_agent_description_1,\n",
    "    client=WorkspaceClient(\n",
    "        host=os.getenv(\"DB_MODEL_SERVING_HOST_URL\"),\n",
    "        token=os.getenv(\"DATABRICKS_GENIE_PAT\")\n",
    "        #token=secret,\n",
    "    ),\n",
    ")\n",
    "\n",
    "GENIE_SPACE_ID_2 = \"01f02ad494421be2953d3e5ba3818319\"\n",
    "genie_agent_description_2 = \"This genie agent can answer any questions concerning hotels, hotel rates and preferences of employees for the hotels.\"\n",
    "\n",
    "genie_agent_2 = GenieAgent(\n",
    "    genie_space_id=GENIE_SPACE_ID_2,\n",
    "    genie_agent_name=\"Genie_DBX_Hotel\",\n",
    "    description=genie_agent_description_2,\n",
    "    client=WorkspaceClient(\n",
    "        host=os.getenv(\"DB_MODEL_SERVING_HOST_URL\"),\n",
    "        token=os.getenv(\"DATABRICKS_GENIE_PAT\")\n",
    "        #token=secret,\n",
    "    ),\n",
    ")\n",
    "\n",
    "GENIE_SPACE_ID_3 = \"01f02ad431cb12a9a93030fac014b105\"\n",
    "genie_agent_description_3 = \"This genie agent can answer any questions concerning employees and employee data. This includes things like name, salaray, job, date of birth (dob) and location.\"\n",
    "\n",
    "genie_agent_3 = GenieAgent(\n",
    "    genie_space_id=GENIE_SPACE_ID_3,\n",
    "    genie_agent_name=\"Genie_DBX_Employee\",\n",
    "    description=genie_agent_description_3,\n",
    "    client=WorkspaceClient(\n",
    "        host=os.getenv(\"DB_MODEL_SERVING_HOST_URL\"),\n",
    "        token=os.getenv(\"DATABRICKS_GENIE_PAT\")\n",
    "        #token=secret,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6c8d2a4-a488-4c8d-b707-4ea73c4062e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Defining our LLM Foundation Model\n",
    "The LLM Foundation Model prprovides the interpretation layer for communications both internally between agents and the supervisor, as well as with the user prompt and response. This is usually the point where we'd want to pick a good foundational model for our task. Remember that every AI application, no matter how general, still needs to have focus and intent for maintenance and stability. Databricks provides several registered models in the `databricks-uc` registry for use and is updating them globally on a regular basis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "567a9b7e-487e-4571-975c-bb19c523506e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define the endpoint and system prompt"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a multi_agent.py\n",
    "#Multi-agent Genie works best with claude 3.7 or gpt 4o models. Both of these are served using the system.ai.* databricks-uc namespace.\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-3-7-sonnet\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49c70958-9b88-4bb5-9b2c-bdbcea881894",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating a code authoring agent\n",
    "Agents can be anything that have the ability to make a logical decision. We've seen up until now that we can use pre-built wrapper functions (`ChatAgent()` and it's Databricks-specific sister `GenieAgent()`) but there are also several pre-built agents available for use natively in Databricks. Let's add a chain of tools (called a toolbox) for another agent we'll call 'Code' to provide the ability to return code suggestions to the invoking entity (whether that's the supervisor or the user). This is a very helpful agent that can actually author, generate and execute code in the background. For security reasons, it's always best practice to put strict guardrails around coding agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dccc09c-2a36-4d96-b204-3e15630a9204",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create another agent to help write code"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a multi_agent.py\n",
    "############################################################\n",
    "# You can also create agents with access to additional tools\n",
    "############################################################\n",
    "toolbox = []\n",
    "\n",
    "#If you want to add more tools to to the toolbox, add additional tools and update the description of this agent\n",
    "uc_tool_names = [\"system.ai.*\"]\n",
    "uc_toolkit = UCFunctionToolkit(function_names=uc_tool_names)\n",
    "\n",
    "toolbox.extend(uc_toolkit.tools)\n",
    "\n",
    "code_agent_description = (\n",
    "    \"The Coder agent specializes in solving programming challenges, generating code snippets, debugging issues, and explaining complex coding concepts.\",\n",
    ")\n",
    "code_agent = create_react_agent(llm, tools=toolbox)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3aaf6dce-0678-46c4-b238-7dec7f516b8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating the supervisor agent\n",
    "\n",
    "**THIS PART IS REALLY IMPORTANT**\n",
    "\n",
    "Now that we have all of our node agents defined for our application graph, let's tie them together with a supervisor agent. This agent is special because it has exclusive access to each of the agents. Although agents can technically talk directly to one another, having a brokerage is a pattern-safe design. We'll always try to decouple and encapsulate agents by responsibility for reasons of security, portability and generalizability. We want our agents to be aware enough of what they can do, but not so aware that they start creating their own graph edges. If we're considering object accountability from a design perspective this keeps the agents 'in line' with their least-privileged responsibility.\n",
    "\n",
    "In a nutshell, what we're doing is we're creating the supervisor agent as concrete implemenation of an iterator that builds it's runnable chain programmatically based on the presence of agents (`workers`) and the generated input description (hence `system_prompt` as the main directive of the application). The supervisor chain in the `supervisor_agent()` function essentially takes all of the upstream definitions and flattens them all into a single, deployable object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbbc9628-fa7c-4456-98b9-571f2808b359",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define the supervisor agent"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a multi_agent.py\n",
    "#NOTE: This cell is just the DEFINITION of the agent graph. All we're doing here is describing how to compose the composite application.\n",
    "\n",
    "#Update the max number of iterations between supervisor and worker nodes before returning to the user. This is how many internal 'conversations' the supervisor has with the other agents. This is a maximum value - if an answer is sufficient with fewer iterations, then great.\n",
    "MAX_ITERATIONS = 5\n",
    "\n",
    "#Add the description for each agent we're going to use as a dictionary\n",
    "worker_descriptions = {\n",
    "    \"Genie_DBX_Billing\": genie_agent_description_1,\n",
    "    \"Genie_DBX_Hotel\": genie_agent_description_2,\n",
    "    \"Genie_DBX_Employee\": genie_agent_description_3,\n",
    "    \"Coder\": code_agent_description,\n",
    "}\n",
    "\n",
    "#Flatten the descriptions into a single string variable\n",
    "formatted_descriptions = \"\\n\".join(\n",
    "    f\"- {name}: {desc}\" for name, desc in worker_descriptions.items()\n",
    ")\n",
    "\n",
    "#Tell the LM in plain language about the agents it has access to\n",
    "system_prompt = f\"Decide between routing between the following workers or ending the conversation if an answer is provided. \\n{formatted_descriptions}\"\n",
    "options = [\"FINISH\"] + list(worker_descriptions.keys())\n",
    "FINISH = {\"next_node\": \"FINISH\"}\n",
    "\n",
    "#Make use of all the above definitions and create the supervisor. This is what we'll be interfacing with and logging in MLFlow.\n",
    "def supervisor_agent(state):\n",
    "    count = state.get(\"iteration_count\", 0) + 1\n",
    "    if count > MAX_ITERATIONS:\n",
    "        return FINISH\n",
    "    \n",
    "    #Define our chaining logic\n",
    "    class nextNode(BaseModel):\n",
    "        next_node: Literal[tuple(options)]\n",
    "\n",
    "    #Assemble the entire chain, defining the supervisor and callable agents with some simple recursion logic.\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    )\n",
    "    supervisor_chain = preprocessor | llm.with_structured_output(nextNode)\n",
    "    next_node = supervisor_chain.invoke(state).next_node\n",
    "    \n",
    "    #If the response routed back to the same node, exit the loop. This identifies when the conversation has reached its peak epoch.\n",
    "    if state.get(\"next_node\") == next_node:\n",
    "        return FINISH\n",
    "    return {\n",
    "        \"iteration_count\": count,\n",
    "        \"next_node\": next_node\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "718116e6-4a3b-4c86-8e96-8f6b169baa45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Defining the node graph\n",
    "This part seems more complicated than it really is. The first thing we need to do is define the conversational structure of the agent nodes and how they interact with the supervisor. Really, all we're doing here is invoking the agent node (any of them) and getting a response based on the input and classifying the response as an assistant response. Once we've done this for each of our agent nodes, we also do it for the supervisor agent and an assembled final answer. We wrap this all together under a `pyfunc()` banner so we can have one fully built, and bundled application. Then we just specify the entry and exit point and then run the whole object through a `compile()` function (part of the `LangGraph.graph` library) to package the whole thing up. Under the `pyfunc()` banner, we can also use MLFlow logging in the `databricks-uc` model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61cd9842-fbda-4e4c-8e23-14dcfb3b8080",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define and build our agent structure"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a multi_agent.py\n",
    "#This is the function that composes the message that interfaces with the LLM.\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": result[\"messages\"][-1].content,\n",
    "                \"name\": name,\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "#This is the callable object that contains the response payload.\n",
    "def final_answer(state):\n",
    "    prompt = \"Using only the content in the messages, respond to the previous user question using the answer given by the other assistant messages.\"\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: state[\"messages\"] + [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    final_answer_chain = preprocessor | llm\n",
    "    return {\"messages\": [final_answer_chain.invoke(state)]}\n",
    "\n",
    "\n",
    "#This object definition is technically just a struct to keep tabs on the agent.\n",
    "class AgentState(ChatAgentState):\n",
    "    next_node: str\n",
    "    iteration_count: int\n",
    "\n",
    "#Use a functools wrapper to build out the actual agent objects based on their descriptors\n",
    "code_node = functools.partial(agent_node, agent=code_agent, name=\"Coder\")\n",
    "genie_node_1 = functools.partial(agent_node, agent=genie_agent_1, name=\"Genie_DBX_Billing\")\n",
    "genie_node_2 = functools.partial(agent_node, agent=genie_agent_2, name=\"Genie_DBX_Hotel\")\n",
    "genie_node_3 = functools.partial(agent_node, agent=genie_agent_3, name=\"Genie_DBX_Employee\")\n",
    "\n",
    "#Build the graph from the nodes, including something to send a result back to whatever's invoking the application (aka final answer).\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Genie_DBX_Billing\", genie_node_1)\n",
    "workflow.add_node(\"Genie_DBX_Hotel\", genie_node_2)\n",
    "workflow.add_node(\"Genie_DBX_Employee\", genie_node_3)\n",
    "workflow.add_node(\"Coder\", code_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)\n",
    "workflow.add_node(\"final_answer\", final_answer)\n",
    "\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "# We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "for worker in worker_descriptions.keys():\n",
    "    workflow.add_edge(worker, \"supervisor\")\n",
    "\n",
    "# Let the supervisor decide which next node to go\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x: x[\"next_node\"],\n",
    "    {**{k: k for k in worker_descriptions.keys()}, \"FINISH\": \"final_answer\"},\n",
    ")\n",
    "workflow.add_edge(\"final_answer\", END)\n",
    "multi_agent = workflow.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f40aeda-0320-4b11-adbb-4025128e0bcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Adding a Chat interface\n",
    "Now that we have our multi_agent() object defined, all we need to do is create a parent function that colours the behaviour of our agent graph. This is defined as a class object that accepts the compiled agent graph as input once instanciated and decorates it with two behaviours. `predict()` is the public behaviour that interfaces with the user or external system. `predict_steam()` is used for the supervisor to keep track of, and maintain conversations with each of the agent nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9886534-fdfc-421f-97c8-6e3bf422738e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Throw everything into our ChatAgent wrapper"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a multi_agent.py\n",
    "class LangGraphChatAgent(ChatAgent):\n",
    "    #Class constructor. This defines how the LangGraphChatAgent is initialized.\n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    #This function is a behaviour that returns a response. It defines the chat structure between the agents. I.E., how they talk back and forth with the supervisor agent. We should probably create an installable library for this since it's pretty typical and can benefit from override and extension functionality.\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        request = {\n",
    "            \"messages\": [m.model_dump_compat(exclude_none=True) for m in messages]\n",
    "        }\n",
    "\n",
    "        messages = []\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                messages.extend(\n",
    "                    ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "                )\n",
    "        return ChatAgentResponse(messages=messages)\n",
    "\n",
    "    #This behaviour is how the supervisor keeps track of internal conversations. This is important as it allows agents to pass context to one another.\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        request = {\n",
    "            \"messages\": [m.model_dump_compat(exclude_none=True) for m in messages]\n",
    "        }\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                yield from (\n",
    "                    ChatAgentChunk(**{\"delta\": msg})\n",
    "                    for msg in node_data.get(\"messages\", [])\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0140571-ee8f-41a1-9a59-acb8b31ae4b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Logging to MLFlow\n",
    "Now that everything is assembled and put together, we can pass the whole thing into MLFlow. Since we've been appending everything to `multi_agent.py` up to this point, the entire definition for the applicaiton can actually be logged just like we would any other ML model. By adding autolog functionality to our application, we can use MLFlow for tracing our application and decision tracking of the conversation with inference tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bea175f-a55e-4706-b8bd-9ab5dc384f26",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create and log the agent group to MLFlow"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a multi_agent.py\n",
    "#Create the agent object, and specify it as the agent object to use when loading the agent back for inference via mlflow.models.set_model()\n",
    "mlflow.langchain.autolog()\n",
    "AGENT = LangGraphChatAgent(multi_agent)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0103f4c-4a1f-40ca-9f3d-28bcd1803ec2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the agent\n",
    "\n",
    "Interact with the agent to test its output. Since this notebook called `mlflow.langchain.autolog()` you can view the trace for each step the agent takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11079f06-9837-4208-af79-2d910058cf2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Kill the python context to validate the file.\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a447d522-1c9c-4454-b1ed-fec2617e38a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create a Personal Access Token (PAT) as a Databricks secret\n",
    "In order to access the Genie Space and its underlying resources, we need to create a PAT\n",
    "- This can either be your own PAT or that of a System Principal ([AWS](https://docs.databricks.com/aws/en/dev-tools/auth/oauth-m2m) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/dev-tools/auth/oauth-m2m)). You will have to rotate this token yourself upon expiry.\n",
    "- Add secrets-based environment variables to a model serving endpoint ([AWS](https://docs.databricks.com/aws/en/machine-learning/model-serving/store-env-variable-model-serving#add-secrets-based-environment-variables) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/store-env-variable-model-serving#add-secrets-based-environment-variables)).\n",
    "- You can reference the table in the deploy docs for the right permissions level for each resource: ([AWS](https://docs.databricks.com/aws/en/generative-ai/agent-framework/deploy-agent#automatic-authentication-passthrough) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/agent-framework/deploy-agent#automatic-authentication-passthrough)).\n",
    "  - Provision with `CAN RUN` on the Genie Space\n",
    "  - Provision with `CAN USE` on the SQL Warehouse powering the Genie Space\n",
    "  - Provision with `SELECT` on underlying Unity Catalog Tables \n",
    "  - Provision with `EXECUTE` on underyling Unity Catalog Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d180a09-5243-4806-a7d3-e9a5664e730d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dbruntime.databricks_repl_context import get_context\n",
    "\n",
    "#Set the variables for the PAT in the Databricks Secrets store\n",
    "secret_scope_name = \"general\"\n",
    "secret_key_name = \"genie_access\"\n",
    "\n",
    "#Inject the variables into the agent for use.\n",
    "os.environ[\"DB_MODEL_SERVING_HOST_URL\"] = \"https://\" + get_context().workspaceUrl\n",
    "assert os.environ[\"DB_MODEL_SERVING_HOST_URL\"] is not None\n",
    "os.environ[\"DATABRICKS_GENIE_PAT\"] = dbutils.secrets.get(\n",
    "    scope=secret_scope_name, key=secret_key_name\n",
    ")\n",
    "assert os.environ[\"DATABRICKS_GENIE_PAT\"] is not None, (\n",
    "    \"The DATABRICKS_GENIE_PAT was not properly set to the PAT secret\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f039ecfd-2679-47bc-99f0-48f0d7ee1bb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Sample testing our application\n",
    "Now that we've written our entire application definition out to `multi_agent.py` and restarted our python interpreter, we can validate the source code that we prepped for deployment. All we need is a simple code stub to simulate how the serving endpoint interfaces with the application. This will show us a breakdown of how each agent is invoked based on different prompts. Experiment with the message prompts for different results. Once we're satisfied, we can consider deploying this to a production-grade serving endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93f75405-f596-4d44-99d3-be114ef27127",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from multi_agent import AGENT, genie_agent_description_1\n",
    "\n",
    "assert genie_agent_description_1 != \"This genie agent can answer ...\", (\n",
    "    \"Remember to update the genie agent description for higher quality answers.\"\n",
    ")\n",
    "input_example = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you help me get the total of my aws costs?\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "AGENT.predict(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b6762af-fb4b-49a8-9501-e107314b3cbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Viewing the logic chain\n",
    "If we want to translate the logic chain into something a bit more human-readable, we can examine the supervisor's conversation with the agents. By iterating through the `predict_stream()` events, we can see what this looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af022e19-a090-41fa-9c9a-d64c43ca334f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Viewing the logic chain as a series"
    }
   },
   "outputs": [],
   "source": [
    "for event in AGENT.predict_stream(input_example):\n",
    "  print(event, \"-----------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00e8a7d1-d556-4594-beb9-da8821f4525f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Validating and flattening the agent logic\n",
    "Notice at the top of each cell for the actual agent composition logic we've used a `%%writefile -a multi_agent.py` command. This takes the contents of each cell and cats them out (via `>>`) to a single file called `multi_agent.py`. Since the agent application is wrapped using `pyfunc()` tools, this is the easiest and most consistent way to log the model artifact in MLFlow for easy registration in Unity Catalog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "299790ba-cd17-4f11-babc-1bc6d3c18cc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log the agent as an MLflow model\n",
    "\n",
    "Log the agent as code from the `agent.py` file. See [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code).\n",
    "\n",
    "### Enable automatic authentication for Databricks resources\n",
    "For the most common Databricks resource types, Databricks supports and recommends declaring resource dependencies for the agent upfront during logging. This enables automatic authentication passthrough when you deploy the agent. With automatic authentication passthrough, Databricks automatically provisions, rotates, and manages short-lived credentials to securely access these resource dependencies from within the agent endpoint.\n",
    "\n",
    "To enable automatic authentication, specify the dependent Databricks resources when calling `mlflow.pyfunc.log_model().`\n",
    "  - **TODO**: If your Unity Catalog tool queries a [vector search index](docs link) or leverages [external functions](docs link), you need to include the dependent vector search index and UC connection objects, respectively, as resources. See docs ([AWS](https://docs.databricks.com/generative-ai/agent-framework/log-agent.html#specify-resources-for-automatic-authentication-passthrough) | [Azure](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/log-agent#resources))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0129622-cdef-4e16-893a-11a059c85729",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Creating the MLFlow defintion\n",
    "When logging a model, project or application to MLFlow, we need to define a few components to tell MLFlow what the project 'looks' like. In other words, we need to provide the context around how it operates. This is what allows MLFlow to serve the project in a consistent and repeatable fashion. Basically, we define the tools and resources that are required for the project to run and be served. Since we're also relying on other Databricks resources (a serving endpoint and a few genie spaces), those need to be both defined and present for the application to run. The same goes for the system and any AI tools that we defined in the code agent. Once all is in order, we can create our MLFlow run that logs our agent application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54a7fdf0-d9a1-4d5b-ab3e-2044da70eaa1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create and log an instance of the agent application in MLFlow"
    }
   },
   "outputs": [],
   "source": [
    "# Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "import mlflow\n",
    "from multi_agent import GENIE_SPACE_ID_1, GENIE_SPACE_ID_2, GENIE_SPACE_ID_3, LLM_ENDPOINT_NAME, toolbox\n",
    "from databricks_langchain import UnityCatalogTool, VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import (\n",
    "    DatabricksFunction,\n",
    "    DatabricksGenieSpace,\n",
    "    DatabricksServingEndpoint,\n",
    ")\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME),\n",
    "    DatabricksGenieSpace(genie_space_id=GENIE_SPACE_ID_1),\n",
    "    DatabricksGenieSpace(genie_space_id=GENIE_SPACE_ID_2),\n",
    "    DatabricksGenieSpace(genie_space_id=GENIE_SPACE_ID_3),\n",
    "]\n",
    "for tool in toolbox:\n",
    "    if isinstance(tool, VectorSearchRetrieverTool):\n",
    "        resources.extend(tool.resources)\n",
    "    elif isinstance(tool, UnityCatalogTool):\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"agent\",\n",
    "        python_model=\"multi_agent.py\",\n",
    "        input_example=input_example,\n",
    "        extra_pip_requirements=[f\"databricks-connect=={get_distribution('databricks-connect').version}\"],\n",
    "        resources=resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "136c836c-8344-4817-80cd-cfbc3f2df3d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pre-deployment agent validation\n",
    "Before registering and deploying the agent, perform pre-deployment checks using the [mlflow.models.predict()](https://mlflow.org/docs/latest/python_api/mlflow.models.html#mlflow.models.predict) API. See Databricks documentation ([AWS](https://docs.databricks.com/en/machine-learning/model-serving/model-serving-debug.html#validate-inputs) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/model-serving-debug#before-model-deployment-validation-checks)).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0aba434a-d6b5-4169-90b0-39b6557a5c6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# mlflow.models.predict(\n",
    "#     model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "#     input_data=input_example,\n",
    "#     env_manager=\"uv\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53dcfac4-0816-4f74-bee6-559740a35235",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the model to Unity Catalog\n",
    "Once our model has been uploaded, we can then register it as the latest version and prepare it for serving. Here we define the location for the registered model in Unity Catalog, where it will be stored and managed as a knowledge object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d10d68c-eaba-432b-a318-333774a999f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"ademianczuk\"\n",
    "schema = \"general\"\n",
    "model_name = \"multi_agent_demo\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3c48cf1-9901-4764-be98-99092ac4142d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy our application\n",
    "The last step is to deploy our application to the Databricks serving endpoint. All we need to do is invoke the `deploy()` function from the databricks core library and pass in our actual access token that's stored in the secrets store. This delegates access to a privileged credential for the agent to act on the user's behalf. Creating the serving infrastructure can take a while (usually about 20 minute for first time deployment) because the entire isolated ephemeral network and container runtime are defined, built, deployed, configured and networked for the duration of the application serving lifetime. If an endpoint is terminated, the deployment descriptors remain from the previous configuration for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "944439bd-53a5-4f8b-a2b2-0cad24b4e397",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "agents.deploy(\n",
    "    UC_MODEL_NAME,\n",
    "    uc_registered_model_info.version,\n",
    "    tags={\"endpointSource\": \"docs\"},\n",
    "    environment_vars={\n",
    "        \"DATABRICKS_GENIE_PAT\": f\"{{{{secrets/{secret_scope_name}/{secret_key_name}}}}}\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c01c102-7010-487c-8a02-46f8e4883748",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next steps\n",
    "\n",
    "After your agent is deployed, you can chat with it in AI playground to perform additional checks, share it with SMEs in your organization for feedback, or embed it in a production application. See Databricks documentation ([AWS](https://docs.databricks.com/en/generative-ai/deploy-agent.html) | [Azure](https://learn.microsoft.com/en-us/azure/databricks/generative-ai/deploy-agent))."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "langgraph-multiagent-genie-pat",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
