{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b52ace02-f199-44bb-b5c3-2eaa35b6aa05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Custom Tools Demo <br/>\n",
    "<img src=\"https://eu-images.contentstack.com/v3/assets/blt6b0f74e5591baa03/blt5d5323f706ef288f/637c0195c162df49beaae102/Untitled_design_(77).png?width=1280&auto=webp&quality=95&format=jpg&disable=upscale\" width=500 /><br/>\n",
    "## Part 2: Assembling The Agentic Application\n",
    "Now that we've prototyped our agents in the previous notebook and worked through debugging them, we can start thinking about composing our application. This version is a little different than a GenieSpaces agentic workflow because we're relying on open libraries rather than the Databricks Genie Agents API. This time we'll need to take into consideration how we're invoking our agents and toolchains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ab39787-142c-4de1-b3f7-b05a698f24c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Designing Our Custom Application\n",
    "\n",
    "In this section, we'll be taking the tools we built previously and composing them into a fully agentic, compound AI system. Using the two prototype agents from the previous notebook, we'll be using the Databricks LangChain agent framework to create a fully-integrated system. Once it's working, we'll be registering our application in our MLFlow registry and serving a version of the model to a front-end application. To get an idea of the relationships between tools, toolboxes, node agents and supervisors, compare this project to a fully integrated GenieAgent version of a compound AI system: <br/>\n",
    "<br/>\n",
    "<img src=\"https://github.com/andrijdemianczuk/Heroic-Hare/blob/main/Notebooks/Custom%20Tools%20for%20Agents%20Demo/Compound%20AI%20Schematic.jpg?raw=true\" width=750/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f29be05b-d0a5-4c83-ab6b-7b9412c9b1ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Assembling our new agents into an compound AI system\n",
    "Since we've already prototyped our two agents (and by extension with two toolboxes) in the last notebook, we can start putting together our agentic application. We'll use the Databricks Agent framework to help us out with this. We'll need to coalesce and decouple our agents (including a supervisor) into new files and publish them to MLFlow for serving.\n",
    "\n",
    "### Building the artifact file\n",
    "Since we've already established the workflow of our tooling, we will need to create a coalesced application file. Technically we could break this up further into separate classes but for the sake of demonstration we will be exporting just a single file for agent registration as an artifact in Unity Catalog with MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e8b0b19-7337-4b88-9d06-b28486e91fd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet langchain-core langchain databricks-vectorsearch langchain-community feedparser\n",
    "%pip install -U -qqq langgraph==0.3.4 databricks-langchain databricks-agents uv\n",
    "%pip install mlflow\n",
    "\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "818ad81c-a439-47f9-ae47-61a1e637d343",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#Check if the asset_agent.py file exists and delete it if it does\n",
    "#This is what allows us to run the notebook over again. If our logic changes, we can also ensure we're not appending garabage to the file or screwing it up.\n",
    "\n",
    "if os.path.exists(\"asset_agent.py\"):\n",
    "    os.remove(\"asset_agent.py\")\n",
    "    print(\"asset_agent.py has been deleted.\")\n",
    "else:\n",
    "    print(\"asset_agent.py does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f9e2e5c-54c8-4da1-822d-2236608242d5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import Dependencies"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a asset_agent.py\n",
    "#Python libs\n",
    "import functools\n",
    "import os\n",
    "from typing import Any, Generator, Literal, Optional, Type\n",
    "import requests\n",
    "import feedparser\n",
    "\n",
    "#Databricks sdk & Databricks langchain implementation\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    UCFunctionToolkit,\n",
    ")\n",
    "# from databricks_langchain.genie import GenieAgent\n",
    "\n",
    "#Langchain tools (langraph is our agent lib)\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.agents import AgentType, initialize_agent, agent\n",
    "from langchain.tools import Tool\n",
    "from langchain.tools import BaseTool\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "\n",
    "#MLflow stuff\n",
    "import mlflow\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "\n",
    "#Parsing libs\n",
    "from pydantic import BaseModel, Field\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ec94050-6c0b-48c7-a26b-9cf0d30f87cd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create an instance of our Foundation Model"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a asset_agent.py\n",
    "#This is the foundation LLM that we'll be using for the basis of our agents\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-3-7-sonnet\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME, extra_params={\"temperature\": 0.3})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a272fca-3e5f-49c9-b6e1-69849cb1b312",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Weather Tool Definition"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a asset_agent.py\n",
    "#Input Schema for the weather class. We'll be using this to compose the tool\n",
    "class WeatherInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location\")\n",
    "    longitude: float = Field(..., description=\"Longitude of the location\")\n",
    "\n",
    "#Create an implementation inheriting the BaseTool abstract class from LangChain. _run() and _arun() are both required implementations. The name and description attributes are also required.\n",
    "class FetchWeatherTool(BaseTool):\n",
    "    name: str = \"fetch_weather\"\n",
    "    description: str = \"Fetch hourly weather temperature data for a given latitude and longitude. When asked about weather, assume that the user is always referring to temperature only. temperature_2m refers to the temperature in degrees celsius.\"\n",
    "    args_schema: Type[BaseModel] = WeatherInput #This is the input schema we defined above.\n",
    "\n",
    "    #The _run() function is always called when invoked. It's essentially doing the same thing as a class constructor, but since we're invoking the class from a toolchain in lieu of instancing the class as an object, this is run instead. This behaviour is what we're inheriting from the BaseTool() class.\n",
    "    def _run(self, latitude: float, longitude: float):\n",
    "        url = \"https://api.open-meteo.com/v1/forecast\"\n",
    "        params = {\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"hourly\": \"temperature_2m\",\n",
    "        }\n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"hourly\"][\"temperature_2m\"][:5]  # Preview\n",
    "        return f\"Failed to fetch data: {response.status_code}\"\n",
    "\n",
    "    def _arun(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"Async not supported.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1907d5ed-5d07-452f-a60b-e519a8a09dfe",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Document Search Tool Definition"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a asset_agent.py\n",
    "class ArxivSearchInput(BaseModel):\n",
    "    query: str = Field(..., description=\"Search keywords for the arXiv research papers\")\n",
    "    max_results: Optional[int] = Field(5, description=\"Max number of papers to return\")\n",
    "\n",
    "class SearchArxivTool(BaseTool):\n",
    "    name: str = \"search_arxiv\"\n",
    "    description: str = \"Search for academic papers on arXiv related to a given keyword.\"\n",
    "    args_schema: Type[BaseModel] = ArxivSearchInput\n",
    "\n",
    "    def _run(self, query: str, max_results: int = 3):\n",
    "        url = \"http://export.arxiv.org/api/query\"\n",
    "        params = {\n",
    "            \"search_query\": f\"all:{query}\",\n",
    "            \"start\": 0,\n",
    "            \"max_results\": max_results,\n",
    "        }\n",
    "        response = requests.get(url, params=params)\n",
    "        feed = feedparser.parse(response.text)\n",
    "        results = []\n",
    "        for entry in feed.entries[:max_results]:\n",
    "            results.append(f\"{entry.title} — {entry.link}\")\n",
    "        return \"\\n\".join(results) if results else \"No papers found.\"\n",
    "\n",
    "    def _arun(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"Async not supported.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b324bd08-9e60-4081-8985-613a79a89c30",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Asset Search Tool Definition"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a asset_agent.py\n",
    "class AssetSearchInput(BaseModel):\n",
    "    asset_query: str = Field(..., description=\"The name of the location or asset to search for\")\n",
    "\n",
    "class SearchAssetsTool(BaseTool):\n",
    "    name: str = \"search_assets\"\n",
    "    description: str = \"Search for geographic or structural asset metadata using OpenStreetMap. \"\n",
    "    args_schema: Type[BaseModel] = AssetSearchInput\n",
    "\n",
    "    def _run(self, asset_query: str):\n",
    "        url = \"https://nominatim.openstreetmap.org/search\"\n",
    "        params = {\"q\": asset_query, \"format\": \"json\"}\n",
    "        headers = {\"User-Agent\": \"LangChainAgent/1.0 (andrij.demianczuk@databricks.com)\"}\n",
    "\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            return f\"Search API returned {response.status_code}. Cannot continue using search_assets.\"\n",
    "        \n",
    "        data = response.json()\n",
    "        if data:\n",
    "            result = data[0]\n",
    "            return f\"{result['display_name']} (lat: {result['lat']}, lon: {result['lon']})\"\n",
    "        else:\n",
    "            return f\"No results found for '{asset_query}'\"\n",
    "\n",
    "    def _arun(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"Async not supported.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57678fbd-6f3c-46e9-8556-f32eecffe4e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agent 1: Weather and Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9ed2d00-3f6d-4095-94d7-440b40667033",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a asset_agent.py\n",
    "weather_tools = [\n",
    "    FetchWeatherTool(),\n",
    "    SearchArxivTool(),\n",
    "]\n",
    "\n",
    "weatherdoc_agent_description = (\n",
    "    \"The Weather and Document agent specializes in retrieving weather (temperature) information from known coordinates. This agent can also retrieve documents from arxiv with a keyword search. This agent focuses on returning useful information to the prompter for weather and research articles. It can have internal conversations to get the most complete infomration from it's tools.\",\n",
    ")\n",
    "\n",
    "weather_doc_conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=5,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "weatherdoc_bot = initialize_agent(\n",
    "    tools=weather_tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    max_iterations=10\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f44578e-cd7f-477a-b549-942eb4428fab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Agent 2: Asset Lookup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5707712b-5df5-405e-b6ba-48f3e355c046",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a asset_agent.py\n",
    "asset_tools = [\n",
    "    SearchAssetsTool()\n",
    "]\n",
    "\n",
    "asset_agent_description = (\n",
    "    \"The asset agent looks up details for asset searches. Typically this will return coordinates but also contains information about the timezone for the assets as well. This input epxects a string for the query and is generally adept at major landmarks in North America.\",\n",
    ")\n",
    "\n",
    "asset_conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=10,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "asset_bot = initialize_agent(\n",
    "    tools=asset_tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    max_iterations=10\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a527568-9cad-4074-be69-cdb2c59c80bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# asset_bot(\"Where is the Saddledome?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e1a4e58-21d5-49f7-b0ef-44eb819aed24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# weatherdoc_bot(\"Can you find me some articles on NVidia's AI Technology?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "171b23d1-2c1b-42ff-955f-2150ea4b3b83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Defining the Supervisor Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64ec7757-7bfa-423a-8821-2a085869d4a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a asset_agent.py\n",
    "#Update the max number of iterations between supervisor and worker nodes before returning to the user. This is how many internal 'conversations' the supervisor has with the other agents. This is a maximum value - if an answer is sufficient with fewer iterations, then great.\n",
    "MAX_ITERATIONS = 10\n",
    "\n",
    "#Add the description for each agent we're going to use as a dictionary\n",
    "worker_descriptions = {\n",
    "    \"Weatherdoc_Agent\":weatherdoc_agent_description,\n",
    "    \"Asset_Agent\":asset_agent_description,\n",
    "}\n",
    "\n",
    "#Flatten the descriptions into a single string variable\n",
    "formatted_descriptions = \"\\n\".join(\n",
    "    f\"- {name}: {desc}\" for name, desc in worker_descriptions.items()\n",
    ")\n",
    "\n",
    "#Tell the LM in plain language about the agents it has access to\n",
    "system_prompt = f\"Decide between routing between the following workers or ending the conversation if an answer is provided. \\n{formatted_descriptions}\"\n",
    "options = [\"FINISH\"] + list(worker_descriptions.keys())\n",
    "FINISH = {\"next_node\": \"FINISH\"}\n",
    "\n",
    "#Make use of all the above definitions and create the supervisor. This is what we'll be interfacing with and logging in MLFlow.\n",
    "def supervisor_agent(state):\n",
    "    count = state.get(\"iteration_count\", 0) + 1\n",
    "    if count > MAX_ITERATIONS:\n",
    "        return FINISH\n",
    "    \n",
    "    #Define our chaining logic\n",
    "    class nextNode(BaseModel):\n",
    "        next_node: Literal[tuple(options)]\n",
    "\n",
    "    #Assemble the entire chain, defining the supervisor and callable agents with some simple recursion logic.\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    )\n",
    "    supervisor_chain = preprocessor | llm.with_structured_output(nextNode)\n",
    "    next_node = supervisor_chain.invoke(state).next_node\n",
    "    \n",
    "    #If the response routed back to the same node, exit the loop. This identifies when the conversation has reached its peak epoch.\n",
    "    if state.get(\"next_node\") == next_node:\n",
    "        return FINISH\n",
    "    return {\n",
    "        \"iteration_count\": count,\n",
    "        \"next_node\": next_node\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "923423e4-2cb9-4463-aae5-2be213bc1046",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Define and build the agent structure"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a asset_agent.py\n",
    "#This is the function that composes the message that interfaces with the LLM.\n",
    "def agent_node(state, agent, name, tools):\n",
    "    prompt = agent.agent.create_prompt(tools=tools)\n",
    "    agent.agent.llm_chain.prompt = prompt\n",
    "    user_messages = [msg for msg in state[\"messages\"] if msg[\"role\"] == \"user\"]\n",
    "    if not user_messages:\n",
    "        raise ValueError(\"No user message found to use as input\")\n",
    "\n",
    "    last_user_message = user_messages[-1][\"content\"]\n",
    "    result = agent.invoke({\"input\": last_user_message})\n",
    "\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": f\"The {name} has determined: {result['output']}\",\n",
    "                \"name\": name,\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "#This is the callable object that contains the response payload.\n",
    "def final_answer(state):\n",
    "    prompt = f\"\"\"You are the final summarizer.\n",
    "\n",
    "                Here is a conversation between a user and multiple assistant agents.\n",
    "\n",
    "                Each assistant agent was responsible for solving part of the user's question.\n",
    "\n",
    "                Your job is to answer the original question as clearly as possible based only on the assistant messages below.\n",
    "\n",
    "                Do not say \"I don't know\" unless no assistant provided a relevant answer.\n",
    "                If multiple assistants provided conflicting or redundant answers, pick the most confident and relevant one.\n",
    "\n",
    "                Respond to the user's original question with the best possible answer.\n",
    "                \"\"\"\n",
    "\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: state[\"messages\"] + [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    final_answer_chain = preprocessor | llm\n",
    "    return {\"messages\": [final_answer_chain.invoke(state)]}\n",
    "\n",
    "\n",
    "#This object definition is technically just a struct to keep tabs on the agent.\n",
    "class AgentState(ChatAgentState):\n",
    "    next_node: str\n",
    "    iteration_count: int\n",
    "\n",
    "#Use a functools wrapper to build out the actual agent objects based on their descriptors\n",
    "weatherdoc_node = functools.partial(agent_node, agent=weatherdoc_bot, name=\"Weatherdoc_Agent\", tools=weather_tools)\n",
    "assetdoc_node = functools.partial(agent_node, agent=asset_bot, name=\"Asset_Agent\", tools=asset_tools)\n",
    "\n",
    "#Build the graph from the nodes, including something to send a result back to whatever's invoking the application (aka final answer).\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Weatherdoc_Agent\", weatherdoc_node)\n",
    "workflow.add_node(\"Asset_Agent\", assetdoc_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)\n",
    "workflow.add_node(\"final_answer\", final_answer)\n",
    "\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "# We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "for worker in worker_descriptions.keys():\n",
    "    workflow.add_edge(worker, \"supervisor\")\n",
    "\n",
    "# Let the supervisor decide which next node to go\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x: x[\"next_node\"],\n",
    "    {**{k: k for k in worker_descriptions.keys()}, \"FINISH\": \"final_answer\"},\n",
    ")\n",
    "workflow.add_edge(\"final_answer\", END)\n",
    "multi_agent = workflow.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0416260-da2f-43df-aa3b-d27b77c4920a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Add a ChatAgent Wrapper"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a asset_agent.py\n",
    "class LangGraphChatAgent(ChatAgent):\n",
    "    #Class constructor. This defines how the LangGraphChatAgent is initialized.\n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    #This function is a behaviour that returns a response. It defines the chat structure between the agents. I.E., how they talk back and forth with the supervisor agent. We should probably create an installable library for this since it's pretty typical and can benefit from override and extension functionality.\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        request = {\n",
    "            \"messages\": [m.model_dump_compat(exclude_none=True) for m in messages]\n",
    "        }\n",
    "\n",
    "        messages = []\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                messages.extend(\n",
    "                    ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "                )\n",
    "        return ChatAgentResponse(messages=messages)\n",
    "\n",
    "    #This behaviour is how the supervisor keeps track of internal conversations. This is important as it allows agents to pass context to one another.\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        request = {\n",
    "            \"messages\": [m.model_dump_compat(exclude_none=True) for m in messages]\n",
    "        }\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                yield from (\n",
    "                    ChatAgentChunk(**{\"delta\": msg})\n",
    "                    for msg in node_data.get(\"messages\", [])\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0a702fa-1348-4caa-bcf5-cf45ab9606cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a asset_agent.py\n",
    "#Create the agent object, and specify it as the agent object to use when loading the agent back for inference via mlflow.models.set_model()\n",
    "mlflow.langchain.autolog()\n",
    "AGENT = LangGraphChatAgent(multi_agent)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50817bd5-b41d-45b7-84d2-94a843153b48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5778e7ef-6a4f-4743-bab2-4b0411efd56d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Kill the python context to validate the file.\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79b2c023-8df3-4395-8443-b10185ec1325",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dbruntime.databricks_repl_context import get_context\n",
    "\n",
    "#Set the variables for the PAT in the Databricks Secrets store\n",
    "secret_scope_name = \"general\"\n",
    "secret_key_name = \"genie_access\"\n",
    "\n",
    "#Inject the variables into the agent for use.\n",
    "os.environ[\"DB_MODEL_SERVING_HOST_URL\"] = \"https://\" + get_context().workspaceUrl\n",
    "assert os.environ[\"DB_MODEL_SERVING_HOST_URL\"] is not None\n",
    "os.environ[\"DATABRICKS_GENIE_PAT\"] = dbutils.secrets.get(\n",
    "    scope=secret_scope_name, key=secret_key_name\n",
    ")\n",
    "assert os.environ[\"DATABRICKS_GENIE_PAT\"] is not None, (\n",
    "    \"The DATABRICKS_GENIE_PAT was not properly set to the PAT secret\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7bd5dda-4be4-4ec6-bb82-781f75323e9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from asset_agent import AGENT\n",
    "\n",
    "input_example = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the weather at 51.0447° N, 114.0719° W?\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "AGENT.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6d35f0e-9703-4a50-9ff2-5a2425ffa49f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from asset_agent import AGENT\n",
    "\n",
    "input_example = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What are the coordinates of the Calgary Saddledome?\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "AGENT.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b992d27a-71d4-4052-8096-ba03eab31aa4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from asset_agent import AGENT\n",
    "\n",
    "input_example = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you find me the top 5 articles about Nvidia?\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "AGENT.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40037323-f02d-4508-9a0d-1c21779b8f9f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create and log an instance of the agent application in MLFlow"
    }
   },
   "outputs": [],
   "source": [
    "# Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "import mlflow\n",
    "from asset_agent import LLM_ENDPOINT_NAME, weather_tools, asset_tools\n",
    "from databricks_langchain import UnityCatalogTool, VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import (\n",
    "    DatabricksFunction,\n",
    "    DatabricksGenieSpace,\n",
    "    DatabricksServingEndpoint,\n",
    ")\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME)\n",
    "]\n",
    "\n",
    "for tool in weather_tools:\n",
    "    if isinstance(tool, UnityCatalogTool):\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "for tool in asset_tools:\n",
    "    if isinstance(tool, UnityCatalogTool):\n",
    "        resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"asset_agent\",\n",
    "        python_model=\"asset_agent.py\",\n",
    "        input_example=input_example,\n",
    "        extra_pip_requirements=[f\"databricks-connect=={get_distribution('databricks-connect').version}\"],\n",
    "        resources=resources\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d27dc1bf-78a2-4f1d-a9a5-8ec40639f7fa",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Register the model to UC"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"ademianczuk\"\n",
    "schema = \"general\"\n",
    "model_name = \"asset_agent\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a551a9ed-5789-4d1a-865b-663ebe6efe42",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Deploy the App"
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "\n",
    "agents.deploy(\n",
    "    UC_MODEL_NAME,\n",
    "    uc_registered_model_info.version,\n",
    "    tags={\"endpointSource\": \"docs\"},\n",
    "    environment_vars={\n",
    "        \"DATABRICKS_GENIE_PAT\": f\"{{{{secrets/{secret_scope_name}/{secret_key_name}}}}}\"\n",
    "    },\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02-Multi-Agent_Resoning_Demo_with_Custom_Tools",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
